```r
---
title: "LAB 6 | Handling Imbalanced Data and Feature Engineering"
author: "Ahad F23607034"
date: "2025-04-27"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

# Step 1: Setup Environment
```{r}
# Install required packages (only if not already installed)
if (!require(data.table)) install.packages("data.table")
if (!require(ROSE)) install.packages("ROSE")
if (!require(recipes)) install.packages("recipes")
if (!require(caret)) install.packages("caret")
if (!require(FactoMineR)) install.packages("FactoMineR")
if (!require(factoextra)) install.packages("factoextra")
if (!require(ggplot2)) install.packages("ggplot2")

# Load libraries
library(data.table)
library(ROSE)
library(recipes)
library(caret)
library(FactoMineR)
library(factoextra)
library(ggplot2)
```

# Step 2: Load the Dataset (Sampled for Posit Cloud)
```{r}
# Read only first 100000 rows due to Posit Cloud memory limits
data <- fread("creditcard.csv", nrows = 100000, stringsAsFactors = FALSE)

# Confirm dataset loaded
cat("Dataset Dimensions: ", dim(data)[1], "rows and", dim(data)[2], "columns\n")
table(data$Class)
```

# Step 3: Handle Imbalanced Data
```{r}
# Random oversampling
set.seed(123)
balanced_data <- ovun.sample(Class ~ ., data = data, method = "over")$data

# Check class distribution after balancing
table(balanced_data$Class)
```

# Step 4: Feature Engineering
```{r}
# 4.1 Binning the 'Amount' column
data$Amount_Binned <- cut(data$Amount, breaks = c(0, 100, 500, 5000, Inf), labels = c("Low", "Medium", "High", "Very High"))

# 4.2 Creating Polynomial Features for 'Time'
recipe_obj <- recipe(Class ~ ., data = data) %>%
  step_poly(Time, degree = 2)

prepped_data <- prep(recipe_obj, training = data) %>%
  bake(new_data = data)

# Preview transformed data
head(prepped_data)
```

## Step 5: PCA (Principal Component Analysis, corrected)
```{r}
# If you get a "no package ‘crayon’" error, install it first:
if (!require(crayon)) install.packages("crayon")

library(crayon)

# Select only numeric columns
numeric_idx <- sapply(prepped_data, is.numeric)
pca_input  <- prepped_data[, numeric_idx]

# Run PCA
pca_result <- PCA(pca_input, graph = FALSE)

# Convert Class to a factor for discrete coloring
class_factor <- factor(prepped_data$Class, levels = c(0,1), labels = c("Valid","Fraud"))

# Visualize the first two principal components
fviz_pca_ind(
  pca_result,
  geom         = "point",
  habillage    = class_factor,      # use factor here
  palette      = c("grey70","red"), # two colors for the two classes
  addEllipses  = TRUE,
  legend.title = "Transaction\nClass"
)
```

# Step 6: Train Random Forest Model
```{r}
# Random Forest Training on Balanced Data
set.seed(123)
model <- train(Class ~ ., data = balanced_data, method = "rf", trControl = trainControl(method = "cv", number = 5))

# Model Summary
print(model)
```

# Step 7: Results Summary
```{r}
cat("Resampling Method: Random Oversampling\n")
cat("Feature Engineering: Amount binning, Polynomial Time feature\n")
cat("Balanced Class Distribution:\n")
print(table(balanced_data$Class))

# PCA Variance Explained by Top 2 Components
expl_var <- sum(pca_result$eig[1:2, "percentage of variance"])
cat("Top 2 PCA components explain approximately", round(expl_var, 1), "% of variance.\n")
```
